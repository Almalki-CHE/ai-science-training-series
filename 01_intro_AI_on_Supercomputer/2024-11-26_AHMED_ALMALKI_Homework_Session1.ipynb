{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0c37e81f-9661-4548-bab6-8168e201dde6",
      "metadata": {
        "id": "0c37e81f-9661-4548-bab6-8168e201dde6",
        "outputId": "4a4b0eff-d8be-4f15-815d-633afa3670df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "previously calculated: y_i = 87.69 * x + 34754.08    loss: 1478200827.641291\n",
            "batch size: 64, m=83.3171, b=39623.4882, loss=1484680151.8482\n",
            "batch size: 128, m=89.9487, b=30712.1200, loss=1479923429.7177\n",
            "batch size: 256, m=89.1945, b=32407.1989, loss=1478455985.4143\n",
            "batch size: 512, m=89.0674, b=32964.9188, loss=1478327532.3610\n",
            "batch size: 64, m=87.0622, b=35513.5321, loss=1477904150.9835\n",
            "batch size: 128, m=92.9847, b=28913.0551, loss=1488099454.6063\n",
            "batch size: 256, m=80.4363, b=41865.5202, loss=1501829305.9264\n",
            "batch size: 512, m=42042.8455, b=71112664.4771, loss=17422359914619604.0000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipydis\n",
        "import time\n",
        "! [ -e ./slimmed_realestate_data.csv ] || wget https://raw.githubusercontent.com/argonne-lcf/ai-science-training-series/main/01_intro_AI_on_Supercomputer/slimmed_realestate_data.csv\n",
        "data = pd.read_csv('slimmed_realestate_data.csv')\n",
        "print(data.columns)\n",
        "data.plot(x='GrLivArea', y='SalePrice',style='.')\n",
        "n = len(data)\n",
        "x = data['GrLivArea'].to_numpy()\n",
        "y = data['SalePrice'].to_numpy()\n",
        "sum_xy = np.sum(x*y)\n",
        "sum_x = np.sum(x)\n",
        "sum_y = np.sum(y)\n",
        "sum_x2 = np.sum(x*x)\n",
        "denominator = n * sum_x2 - sum_x * sum_x\n",
        "m = (n * sum_xy - sum_x * sum_y) / denominator\n",
        "b = (sum_y * sum_x2 - sum_x * sum_xy) / denominator\n",
        "print('y = %f * x + %f' % (m,b))\n",
        "\n",
        "# saving these for later comparison\n",
        "m_calc = m\n",
        "b_calc = b\n",
        "def plot_data(x,y,m,b,plt = plt):\n",
        "  # plot our data points with 'bo' = blue circles\n",
        "  plt.plot(x,y,'bo')\n",
        "  # create the line based on our linear fit\n",
        "  # first we need to make x points\n",
        "  # the 'arange' function generates points between two limits (min,max)\n",
        "  linear_x = np.arange(x.min(),x.max())\n",
        "  # now we use our fit parameters to calculate the y points based on our x points\n",
        "  linear_y = linear_x * m + b\n",
        "  # plot the linear points using 'r-' = red line\n",
        "  plt.plot(linear_x,linear_y,'r-',label='fit')\n",
        "plot_data(x,y,m,b)\n",
        "def model(x,m,b):\n",
        "   return m * x + b\n",
        "def loss(x,y,m,b):\n",
        "   y_predicted = model(x,m,b)\n",
        "   return np.power( y - y_predicted, 2 )\n",
        "def updated_m(x,y,m,b,learning_rate):\n",
        "   dL_dm = - 2 * x * (y - model(x,m,b))\n",
        "   dL_dm = np.mean(dL_dm)\n",
        "   return m - learning_rate * dL_dm\n",
        "def updated_b(x,y,m,b,learning_rate):\n",
        "   dL_db = - 2 * (y - model(x,m,b))\n",
        "   dL_db = np.mean(dL_db)\n",
        "   return b - learning_rate * dL_db\n",
        "m = 5.\n",
        "b = 1000.\n",
        "print('y_i = %.2f * x + %.2f' % (m,b))\n",
        "l = loss(x,y,m,b)\n",
        "print('first 10 loss values: ',l[:10])\n",
        "learning_rate = 1e-9\n",
        "m = updated_m(x,y,m,b,learning_rate)\n",
        "b = updated_b(x,y,m,b,learning_rate)\n",
        "print('y_i = %.2f * x + %.2f     previously calculated: y_i = %.2f * x + %.2f' % (m,b,m_calc,b_calc))\n",
        "plot_data(x,y,m,b)\n",
        "# set our initial slope and intercept\n",
        "m = 5.\n",
        "b = 1000.\n",
        "# batch_size = 60\n",
        "# set a learning rate for each parameter\n",
        "learning_rate_m = 1e-7\n",
        "learning_rate_b = 1e-1\n",
        "# use these to plot our progress over time\n",
        "loss_history = []\n",
        "# convert panda data to numpy arrays, one for the \"Ground Living Area\" and one for \"Sale Price\"\n",
        "data_x = data['GrLivArea'].to_numpy()\n",
        "data_y = data['SalePrice'].to_numpy()\n",
        "# we run our loop N times\n",
        "loop_N = 30\n",
        "for i in range(loop_N):\n",
        "   # update our slope and intercept based on the current values\n",
        "   m = updated_m(data_x,data_y,m,b,learning_rate_m)\n",
        "   b = updated_b(data_x,data_y,m,b,learning_rate_b)\n",
        "\n",
        "   # calculate the loss value\n",
        "   loss_value = np.mean(loss(data_x,data_y,m,b))\n",
        "\n",
        "   # keep a history of our loss values\n",
        "   loss_history.append(loss_value)\n",
        "\n",
        "   # print our progress\n",
        "   print('[%03d]  dy_i = %.2f * x + %.2f     previously calculated: y_i = %.2f * x + %.2f    loss: %f' % (i,m,b,m_calc,b_calc,loss_value))\n",
        "\n",
        "   # close/delete previous plots\n",
        "   plt.close('all')\n",
        "\n",
        "   # create a 1 by 2 plot grid\n",
        "   fig,ax = plt.subplots(1,2,figsize=(18,6),dpi=80)\n",
        "   # lot our usual output\n",
        "   plot_data(data_x,data_y,m,b,ax[0])\n",
        "\n",
        "   # here we also plot the calculated linear fit for comparison\n",
        "   line_x = np.arange(data_x.min(),data_x.max())\n",
        "   line_y = line_x * m_calc + b_calc\n",
        "   ax[0].plot(line_x,line_y,'b-',label='calculated')\n",
        "   # add a legend to the plot and x/y labels\n",
        "   ax[0].legend()\n",
        "   ax[0].set_xlabel('square footage')\n",
        "   ax[0].set_ylabel('sale price')\n",
        "\n",
        "   # plot the loss\n",
        "   loss_x = np.arange(0,len(loss_history))\n",
        "   loss_y = np.asarray(loss_history)\n",
        "   ax[1].plot(loss_x,loss_y, 'o-')\n",
        "   ax[1].set_yscale('log')\n",
        "   ax[1].set_xlabel('loop step')\n",
        "   ax[1].set_ylabel('loss')\n",
        "   plt.show()\n",
        "   # gives us time to see the plot\n",
        "   time.sleep(2.5)\n",
        "   # clears the plot when the next plot is ready to show.\n",
        "   ipydis.clear_output(wait=True)\n",
        "#HW\n",
        "x = data['GrLivArea'].to_numpy()\n",
        "y = data['SalePrice'].to_numpy()\n",
        "\n",
        "def train(batch_size, epochs=30, learning_rate_m = 1e-7, learning_rate_b = 1e-1):\n",
        "    loss_history = []\n",
        "    num_batches = len(data)//batch_size\n",
        "    loop_N = epochs*num_batches\n",
        "    m = 5.\n",
        "    b = 1000.\n",
        "    for i in range(loop_N):\n",
        "        data_batch = data.sample(batch_size)\n",
        "        data_x = data_batch['GrLivArea'].to_numpy()\n",
        "        data_y = data_batch['SalePrice'].to_numpy()\n",
        "        # update our slope and intercept based on the current values\n",
        "        m = updated_m(data_x,data_y,m,b,learning_rate_m)\n",
        "        b = updated_b(data_x,data_y,m,b,learning_rate_b)\n",
        "\n",
        "        # calculate the loss value\n",
        "        loss_value = np.mean(loss(data_x,data_y,m,b))\n",
        "\n",
        "        # keep a history of our loss values\n",
        "        loss_history.append(loss_value)\n",
        "    #loss_last_epoch = np.sum(loss_history[-num_batches:]*batch_size)/len(data)\n",
        "    return m, b, np.mean(loss(x,y,m,b))\n",
        "print('previously calculated: y_i = %.2f * x + %.2f    loss: %f' % (m_calc,b_calc,loss_value))\n",
        "\n",
        "for bs in 64, 128, 256, 512:\n",
        "    m, b, l = train(bs, epochs=30)\n",
        "    print(f\"batch size: {bs}, m={m:.4f}, b={b:.4f}, loss={l:.4f}\")\n",
        "for i in 1, 2, 4, 8:\n",
        "    bs, lrm, lrb = np.array([64, 1e-7, 1e-1])*i\n",
        "    bs = int(bs)\n",
        "    m, b, l = train(int(bs), epochs=30, learning_rate_m = lrm, learning_rate_b = lrb)\n",
        "    print(f\"batch size: {bs}, m={m:.4f}, b={b:.4f}, loss={l:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53277917-adc3-4d7f-82a7-4a33b0356558",
      "metadata": {
        "id": "53277917-adc3-4d7f-82a7-4a33b0356558"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}